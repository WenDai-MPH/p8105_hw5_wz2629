---
title: "Homework 5"
author: "Wen Dai"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)
library(rvest)
set.seed(123)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```
## Problem 1

For this problem, we are interested in data gathered and made public by _The Washington Post_ on homicides in 50 large U.S. cities. The code chunk below imports and cleans the data.

```{r}
homicide_df = 
  read_csv("data1/homicide-data.csv", na = c("", "NA", "Unknown")) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved"
    )
  ) %>% 
  filter(city_state != "Tulsa, AL") 
```

The resulting dataframe has `r nrow(homicide_df)` entries, on variables that include the victim name, race, age, and sex; the date the homicide was reported; and the location of the homicide. In cleaning, I created a `city_state` variable that includes both city and state, and a `resolution` variable to indicate whether the case was closed by arrest. I also excluded one entry in Tulsa, AL, which is not a major US city and is most likely a data entry error. 

In the next code chunk, I group within cities and summarize to produce the total number of homicides and the number that are solved. 

```{r}
city_homicide_df = 
  homicide_df %>% 
  select(city_state, disposition, resolution) %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolution == "unsolved"))
```

Focusing only on Baltimore, MD, I can use the `prop.test` and `broom::tidy` functions to obtain an estimate and CI of the proportion of unsolved homicides in that city. The table below shows those values.

```{r}
bmore_test = 
  prop.test(
    x = filter(city_homicide_df, city_state == "Baltimore, MD") %>% pull(hom_unsolved),
    n = filter(city_homicide_df, city_state == "Baltimore, MD") %>% pull(hom_total)) 

broom::tidy(bmore_test) %>% 
  knitr::kable(digits = 3)
```

Building on this code, I can use functions in the `purrr` package to obtain estimates and CIs for the proportion of unsolved homicides in each city in my dataset. The code below implements this analysis. 

```{r}
test_results = 
  city_homicide_df %>% 
  mutate(
    prop_tests = map2(hom_unsolved, hom_total, \(x, y) prop.test(x = x, n = y)),
    tidy_tests = map(prop_tests, broom::tidy)) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  mutate(city_state = fct_reorder(city_state, estimate))
```

Finally, I make a plot showing the estimate (and CI) of the proportion of unsolved homicides in each city.

```{r}
test_results %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

This figure suggests a very wide range in the rate at which homicides are solved -- Chicago is noticeably high and, given the narrowness of the CI, likely is the location of many homicides. 

# Problem 2

Part I: Create a tidy data frame containing data from all participants, including the subject ID, arm, and observations over time:

* step 1: Use list.files function to create a dataframe that containing all file names

* step 2: Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe. 

* Step 3: I tidied the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary

```{r}
names=list.files(path = "data", full.names = TRUE) 
data1=sub(".csv","",names)

load_df=function(path)
{
  df= read_csv(path) |> 
  janitor::clean_names() 
}


list_path=
  list(
a="data/con_01.csv",
b="data/con_02.csv",
c="data/con_03.csv", 
d="data/con_04.csv",
e="data/con_05.csv",
f="data/con_06.csv",
g="data/con_07.csv",
h="data/con_08.csv",
i="data/con_09.csv",
g="data/con_10.csv",
k="data/exp_01.csv",
l="data/exp_02.csv",
m="data/exp_03.csv", 
n="data/exp_04.csv",
o="data/exp_05.csv",
p="data/exp_06.csv",
q="data/exp_07.csv",
r="data/exp_08.csv",
s="data/exp_09.csv",
t="data/exp_10.csv"
  )


tidy_df=data.frame(name =data1) |> 
 separate(col =name, into = c("path", "observation1"), sep = "/", remove = FALSE) |> 
  mutate(subject=observation1) |> 
  separate(col =observation1, into=c("group","b"), sep = "_", remove = FALSE) |> 
  select(subject,group) |> 
  mutate(table=map(list_path,load_df)) |>
  unnest(table)

final_tidy_df=tidy_df |>  pivot_longer(week_1:week_8,
               names_to="week",
               names_prefix = "week_",
               values_to = "result") 

final_tidy_df|> knitr::kable(digits = 3)
```

Part II: Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

* Step 1: Make a spaghetti plot showing observations on each subject over time

* Step 2: comment on differences between groups

```{r}


ggplot(final_tidy_df, aes(x = week, y =result, group =subject , color = group)) +
  geom_line() +facet_grid(~group)+
  labs(title = "Spaghetti Plot of observations on each subject over time",
       x = "Week",
       y = "Result on each subject") 

```

### Comment: 
The spaghetti plot provides a comparative visual representation of the trajectories between 'con' (control) and 'exp' (experimental) groups across an eight-week span. The control group's pattern remains relatively unchanged throughout the period, with observation values fluctuating around a constant mean, indicating a stable condition without significant internal variations. In contrast, the experimental group reveals a progressive increase in observation values, indicating a clear trend. This upward trajectory becomes particularly evident after the fourth week, marking a divergence from the control group. The variability within the experimental group also increases over time, suggesting individual differences in response to the experimental conditions. By the final week, the experimental group's observation values are notably higher than those of the control group, suggesting that the experimental conditions may have had a systematic effect on the measured outcomes.


# Problem 3:

Part I: Conduct a simulation to explore power in a one-sample t-test.

* Step 1:
First set the following design elements:Fix n=30 |Fix σ=5|Set μ=0|
Generate 5000 datasets from the model
x∼Normal[μ,σ]

For each dataset, save μ̂ and the p-value arising from a test of H:μ=0 using α=0.05

```{r}

t_test <- function(mean) {
  data <- tibble(
    x = rnorm(30, mean = mean, sd = 5)
  ) 
  
  test_result <- t.test(data[["x"]]) 
  tidy_result <-broom::tidy(test_result) 
}

normal_df_zero=
  expand_grid(
    mean_size=c(0),
    iter=1:5000,
  )|> 
  mutate(estimate_df=map(mean_size,t_test)) |> unnest(estimate_df)|> select(estimate,p.value) 

normal_df_zero 
```

* Step 2: 
Repeat the above for μ={1,2,3,4,5,6}

```{r}
normal_df=expand_grid(
    mean_size=c(0,1,2,3,4,5,6),
    iter=1:5000,
  )|> 
  mutate(estimate_df=map(mean_size,t_test)) |> unnest(estimate_df)|> select(mean_size,estimate,p.value) 

normal_df
```

Part II: LET'S PLOT!

* Step 1: Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

```{r}
power_df =normal_df |> 
  mutate(rejected = ifelse(p.value < 0.05, 1, 0)) |> 
  group_by(mean_size) |> 
  summarise(power = mean(rejected))


ggplot(power_df, aes(mean_size, y=power)) +
  geom_path() +
  theme_minimal() +
  labs(title='Power vs. True Value of μ',
       x='True Value of μ',
       y='Power (Proportion of Null Rejected)')
```

### Comment: 
This Plot elucidates a positively correlated, non-linear relationship between effect size and statistical power.
Initially, with the true mean (μ) near the null hypothesis (possibly zero here), the test's power is low due to the small effect size blending with random variation. As the effect size grows, power rapidly increases, signifying a higher likelihood of detecting the true effect. After reaching a certain point, further increases in effect size have minimal impact on power, as it nears its maximum capacity.

